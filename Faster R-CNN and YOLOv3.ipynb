{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:57:21.074180Z",
     "start_time": "2024-12-19T11:57:19.870727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Specify paths to YOLO files\n",
    "weights_path = r\"C:\\Users\\DELL\\ML\\yolov3\\yolov3.weights\"\n",
    "config_path = r\"C:\\Users\\DELL\\ML\\yolov3\\yolov3.cfg\"\n",
    "classes_path = r\"C:\\Users\\DELL\\ML\\yolov3\\coco.names\"\n",
    "\n",
    "# Verify that all files exist\n",
    "if not os.path.exists(weights_path):\n",
    "    raise FileNotFoundError(f\"YOLO weights file not found: {weights_path}\")\n",
    "if not os.path.exists(config_path):\n",
    "    raise FileNotFoundError(f\"YOLO configuration file not found: {config_path}\")\n",
    "if not os.path.exists(classes_path):\n",
    "    raise FileNotFoundError(f\"Classes file not found: {classes_path}\")\n",
    "\n",
    "# Load class labels\n",
    "with open(classes_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(f\"Loaded {len(classes)} classes: {classes}\")\n",
    "\n",
    "# Load YOLO model\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Get output layer names\n",
    "layer_names = net.getLayerNames()\n",
    "unconnected_layers = net.getUnconnectedOutLayers()\n",
    "\n",
    "# Adjust for proper indexing\n",
    "output_layers = [layer_names[i - 1] for i in unconnected_layers.flatten()]\n",
    "\n",
    "print(\"YOLO model loaded successfully.\")\n",
    "print(f\"Output layers: {output_layers}\")\n"
   ],
   "id": "c449808d4f627bbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 classes: ['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "YOLO model loaded successfully.\n",
      "Output layers: ['yolo_82', 'yolo_94', 'yolo_106']\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Code Reading",
   "id": "207c80e84ec4f475"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preprocessing the Image",
   "id": "17088055f8d88c7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:57:21.152146Z",
     "start_time": "2024-12-19T11:57:21.138640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess image\n",
    "def preprocess_image(image_path, input_size=416):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Resize image to fit YOLO's input size (416x416 or any other specific size)\n",
    "    blob = cv2.dnn.blobFromImage(image, 0.00392, (input_size, input_size), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    return image, blob, height, width\n"
   ],
   "id": "65eb5beab7d4911b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading YOLO Model (with weights and config)",
   "id": "f465e4728da328e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:57:21.263591Z",
     "start_time": "2024-12-19T11:57:21.242603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_yolo_model(weights_path, config_path):\n",
    "    # Load YOLO network using OpenCV DNN module\n",
    "    net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "    # Get YOLO's output layers\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return net, output_layers\n"
   ],
   "id": "52456975d7ea3e92",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Obtaining Detections (Forward Pass)",
   "id": "922f00c75e525b36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:57:21.311489Z",
     "start_time": "2024-12-19T11:57:21.294500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_detections(net, blob, output_layers):\n",
    "    # Set the blob as input to the network and perform a forward pass\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    return outs\n"
   ],
   "id": "28c598bc1604766f",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Post-processing the Detections",
   "id": "18ad23f9095936c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:57:21.356603Z",
     "start_time": "2024-12-19T11:57:21.339326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def post_process(image, outs, confidence_threshold=0.5, nms_threshold=0.4):\n",
    "    # Get image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Initialize lists for detected objects\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Loop over all the detections from the output layers\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]  # Get scores (object class probabilities)\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > confidence_threshold:\n",
    "                # Get the bounding box coordinates (x, y, width, height)\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Calculate top-left corner of the bounding box\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Store the box, class id, and confidence\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply Non-Maximum Suppression to remove redundant boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, nms_threshold)\n",
    "\n",
    "    return indices, boxes, confidences, class_ids\n"
   ],
   "id": "7cd42f60fa4a910f",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Displaying the Results",
   "id": "433912e80287518c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:57:21.400196Z",
     "start_time": "2024-12-19T11:57:21.380221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def draw_boxes(image, indices, boxes, confidences, class_ids, classes, colors=None):\n",
    "    # Draw bounding boxes on the image\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for i in indices.flatten():\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])  # Get the class label\n",
    "        confidence = confidences[i]\n",
    "\n",
    "        # Set the color (you can define a list of colors for different classes)\n",
    "        color = (0, 255, 0) if colors is None else colors[class_ids[i]]\n",
    "\n",
    "        # Draw rectangle and label\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(image, f\"{label} {confidence:.2f}\", (x, y - 10), font, 0.5, color, 2)\n",
    "\n",
    "    # Display the output image\n",
    "    cv2.imshow(\"YOLOv3 Output\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "90bfc111af2a3c33",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-19T12:01:25.259687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def main(image_path, weights_path, config_path, classes_path):\n",
    "    # 1. Load classes (COCO class names)\n",
    "    with open(classes_path, \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # 2. Load and preprocess the image\n",
    "    image, blob, height, width = preprocess_image(image_path)\n",
    "\n",
    "    # 3. Load YOLO model\n",
    "    net, output_layers = load_yolo_model(weights_path, config_path)\n",
    "\n",
    "    # 4. Get detections\n",
    "    outs = get_detections(net, blob, output_layers)\n",
    "\n",
    "    # 5. Post-process detections\n",
    "    indices, boxes, confidences, class_ids = post_process(image, outs)\n",
    "\n",
    "    # 6. Draw boxes on image\n",
    "    draw_boxes(image, indices, boxes, confidences, class_ids, classes)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with the paths to your files\n",
    "    image_path = r\"C:\\Users\\DELL\\ML\\yolov3\\data\\images\\bus.jpg\"\n",
    "    image_path = r\"C:\\Users\\DELL\\ML\\yolov3\\data\\images\\zidane.jpg\"# Input image\n",
    "    # Specify paths to YOLO files\n",
    "    weights_path = r\"C:\\Users\\DELL\\ML\\yolov3\\yolov3.weights\"\n",
    "    config_path = r\"C:\\Users\\DELL\\ML\\yolov3\\yolov3.cfg\"\n",
    "    classes_path = r\"C:\\Users\\DELL\\ML\\yolov3\\coco.names\"\n",
    "\n",
    "    main(image_path, weights_path, config_path, classes_path)\n"
   ],
   "id": "e7f920434b535e60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Estimation using trained weights",
   "id": "a077e6a373c5886d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO\n",
    "def load_yolo_model(weights_path, config_path):\n",
    "    net = cv2.dnn.readNet(weights_path, config_path)\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return net, output_layers\n",
    "\n",
    "# Preprocess image\n",
    "def preprocess_image(image_path, input_size=416):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image not found at the path: {image_path}\")\n",
    "    height, width = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(image, 0.00392, (input_size, input_size), (0, 0, 0), True, crop=False)\n",
    "    return image, blob, height, width\n",
    "\n",
    "# Perform object detection and draw bounding boxes\n",
    "def post_process(image, outs, classes, height, width):\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:  # You can adjust this threshold\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indices:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            color = (0, 255, 0)  # Green color for bounding box\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(image, f\"{label} {confidence}\", (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Main function to perform object detection\n",
    "def detect_objects(image_path, weights_path, config_path, classes_path):\n",
    "    # Load class names\n",
    "    with open(classes_path, \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Preprocess image\n",
    "    image, blob, height, width = preprocess_image(image_path)\n",
    "\n",
    "    # Load YOLO model\n",
    "    net, output_layers = load_yolo_model(weights_path, config_path)\n",
    "\n",
    "    # Perform forward pass to get outputs\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Post-process the outputs to draw bounding boxes\n",
    "    result_image = post_process(image, outs, classes, height, width)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow(\"YOLO Detection\", result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the output image with bounding boxes\n",
    "    output_image_path = \"output_image.jpg\"\n",
    "    cv2.imwrite(output_image_path, result_image)\n",
    "    print(f\"Output saved at: {output_image_path}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to the necessary files\n",
    "    image_path = r\"C:\\Users\\DELL\\ML\\yolov3\\data\\images\\zidane.jpg\"# Input image\n",
    "    # Specify paths to YOLO files\n",
    "    weights_path = r\"C:\\Users\\DELL\\ML\\yolov3\\yolov3_2000.weights\"\n",
    "    config_path = r\"C:\\Users\\DELL\\ML\\yolov3\\yolov3.cfg\"\n",
    "    classes_path = r\"C:\\Users\\DELL\\ML\\yolov3\\coco.names\"\n",
    "\n",
    "    # Perform object detection\n",
    "    detect_objects(image_path, weights_path, config_path, classes_path)\n"
   ],
   "id": "ca3d1744243c33e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a file for study",
   "id": "86e9a56cf3d4606"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert Annotations to YOLO Format",
   "id": "9040a3626513162b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to convert Pascal VOC XML annotation to YOLO format\n",
    "def convert_xml_to_yolo(xml_file, image_width, image_height):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    yolo_annotations = []\n",
    "    for obj in root.findall('object'):\n",
    "        class_name = obj.find('name').text\n",
    "        xmin = int(obj.find('bndbox/xmin').text)\n",
    "        ymin = int(obj.find('bndbox/ymin').text)\n",
    "        xmax = int(obj.find('bndbox/xmax').text)\n",
    "        ymax = int(obj.find('bndbox/ymax').text)\n",
    "\n",
    "        # Calculate YOLO format coordinates (relative to image size)\n",
    "        x_center = (xmin + xmax) / 2 / image_width\n",
    "        y_center = (ymin + ymax) / 2 / image_height\n",
    "        width = (xmax - xmin) / image_width\n",
    "        height = (ymax - ymin) / image_height\n",
    "\n",
    "        # Class ID (set according to your dataset)\n",
    "        class_id = 0  # Modify this based on the number of classes in your dataset\n",
    "\n",
    "        yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "    return yolo_annotations\n",
    "\n",
    "# Function to process all XML annotations in a directory and convert to YOLO format\n",
    "def convert_annotations_to_yolo(annotation_dir, image_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for xml_file in os.listdir(annotation_dir):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            # Get the image corresponding to the annotation\n",
    "            image_path = os.path.join(image_dir, xml_file.replace('.xml', '.jpg'))\n",
    "            image = cv2.imread(image_path)\n",
    "            image_height, image_width = image.shape[:2]\n",
    "\n",
    "            # Convert XML annotation to YOLO format\n",
    "            yolo_annotations = convert_xml_to_yolo(\n",
    "                os.path.join(annotation_dir, xml_file),\n",
    "                image_width, image_height\n",
    "            )\n",
    "\n",
    "            # Write YOLO annotations to file\n",
    "            yolo_annotation_file = os.path.join(output_dir, xml_file.replace('.xml', '.txt'))\n",
    "            with open(yolo_annotation_file, 'w') as f:\n",
    "                for annotation in yolo_annotations:\n",
    "                    f.write(f\"{annotation}\\n\")\n",
    "\n",
    "# Example usage\n",
    "annotation_dir = 'simpsons_dataset/annotations'\n",
    "image_dir = 'simpsons_dataset/images'\n",
    "output_dir = 'simpsons_dataset/yolo_annotations'\n",
    "\n",
    "convert_annotations_to_yolo(annotation_dir, image_dir, output_dir)\n"
   ],
   "id": "5d51b0f10ae3a5b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set Up YOLO Training Files",
   "id": "9ebb3cf98aeeb036"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "# Function to generate train.txt and test.txt files\n",
    "def generate_data_files(image_dir, output_dir, split_ratio=0.8):\n",
    "    images = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "    train_size = int(len(images) * split_ratio)\n",
    "\n",
    "    # Create train.txt and test.txt files\n",
    "    with open(os.path.join(output_dir, 'train.txt'), 'w') as f_train, \\\n",
    "         open(os.path.join(output_dir, 'test.txt'), 'w') as f_test:\n",
    "        for i, image in enumerate(images):\n",
    "            if i < train_size:\n",
    "                f_train.write(image + '\\n')\n",
    "            else:\n",
    "                f_test.write(image + '\\n')\n",
    "\n",
    "# Example usage\n",
    "generate_data_files('simpsons_dataset/images', 'simpsons_dataset')\n"
   ],
   "id": "4fbf69110328eddf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(Advanced) Code Reading\n",
    "\n",
    "The important parts of the YOLOv3 paper that influence the code implementation are:\n",
    "\n",
    "The architecture of the single convolutional network.\n",
    "Bounding box regression and anchor boxes.\n",
    "Detection at multiple scales.\n",
    "Objectness score (confidence) and class predictions.\n",
    "The Darknet53 backbone for feature extraction.\n",
    "The loss function, which combines multiple components.\n",
    "\n",
    "\n",
    "These concepts are all implemented and reflected in the codebase through the configuration files, network definitions, and training code."
   ],
   "id": "5215e672c235a956"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
